{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPiPC7kM8kPwNVoGFuezv0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d568e19c1c5941b99f8db76e89bbdc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0028cdc892534174b2f2e638c17f528f",
              "IPY_MODEL_1493cfac3c9649b4b2de9496bf9fcd1d",
              "IPY_MODEL_b465467697874741a74108c7eb2bfb13"
            ],
            "layout": "IPY_MODEL_9b585164c16c4823affc7eae9e73a3f9"
          }
        },
        "0028cdc892534174b2f2e638c17f528f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a40b05b0030a46bcba7535366912e863",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e8d20f734efd4867b29e13cbde48a2d5",
            "value": "Map:â€‡100%"
          }
        },
        "1493cfac3c9649b4b2de9496bf9fcd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2eaa2bbe5f4e80a7a685b1f718066a",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24a49d8195d147b0a40724fffe800a6f",
            "value": 1600
          }
        },
        "b465467697874741a74108c7eb2bfb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8bc72d0f5cd49909286c815977e1c1f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e664f67bfa4a46c58849751c9438be8e",
            "value": "â€‡1600/1600â€‡[00:01&lt;00:00,â€‡962.28â€‡examples/s]"
          }
        },
        "9b585164c16c4823affc7eae9e73a3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a40b05b0030a46bcba7535366912e863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d20f734efd4867b29e13cbde48a2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2eaa2bbe5f4e80a7a685b1f718066a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24a49d8195d147b0a40724fffe800a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8bc72d0f5cd49909286c815977e1c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e664f67bfa4a46c58849751c9438be8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e829a2d06cea42fd98b8fdb71b6ff07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9420bc4c45d44992b33ca43c7b60b894",
              "IPY_MODEL_89148a0cc17c40d3b82b0f08cc57cc24",
              "IPY_MODEL_a3f24a6b3a2c4dafbb655dbfdbbe5d30"
            ],
            "layout": "IPY_MODEL_4b95cc38fc1b4e3f8ceafa01d8c8fb9e"
          }
        },
        "9420bc4c45d44992b33ca43c7b60b894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67969a6448e947c48cfd284b621b2480",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bfd33096139b4a7691a87f61314cb84e",
            "value": "Map:â€‡100%"
          }
        },
        "89148a0cc17c40d3b82b0f08cc57cc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33fc4a0f12f6478d86036f7a09c87e32",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4b83f63f6f34dfdac0722b2bdfc625a",
            "value": 400
          }
        },
        "a3f24a6b3a2c4dafbb655dbfdbbe5d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9541f61376047cb83ff516db7e705d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51158cab3cf44830a0ad3fb3a877039b",
            "value": "â€‡400/400â€‡[00:00&lt;00:00,â€‡763.98â€‡examples/s]"
          }
        },
        "4b95cc38fc1b4e3f8ceafa01d8c8fb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67969a6448e947c48cfd284b621b2480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd33096139b4a7691a87f61314cb84e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33fc4a0f12f6478d86036f7a09c87e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b83f63f6f34dfdac0722b2bdfc625a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9541f61376047cb83ff516db7e705d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51158cab3cf44830a0ad3fb3a877039b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alixa2003/AI-ML-Internship-Tasks-Month2/blob/main/DHC_Task5_Final_Auto_Tagging_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Task5: Auto-Tagging System usinf Few-shot & Zero-Shot Prompting.**"
      ],
      "metadata": {
        "id": "ytw3IVRGfQSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importing Libraries**"
      ],
      "metadata": {
        "id": "NarpnKnyfeHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "_M8_P7NOc2ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "8uokuvjFfjCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    print(f\"Loading dataset from: {file_path}\")\n",
        "\n",
        "    # 1. Load the CSV file\n",
        "    df = pd.read_csv(file_path, encoding='latin1')\n",
        "\n",
        "    # 2. Combine Subject and Body\n",
        "    # We combine them to give the LLM the full context of the user's issue.\n",
        "    df['text'] = df['subject'].fillna('') + \" \\n \" + df['body'].fillna('')\n",
        "\n",
        "    # 3. Extract Tags\n",
        "    # Tags are spread across columns 'tag_1' to 'tag_8'. We need to collect them into a single list.\n",
        "    tag_cols = [f'tag_{i}' for i in range(1, 9)]\n",
        "\n",
        "    def collect_tags(row):\n",
        "        # List comprehension to get values that are not Null/NaN\n",
        "        tags = [str(row[col]) for col in tag_cols if pd.notna(row[col])]\n",
        "        return list(set(tags)) # Remove duplicates if any\n",
        "\n",
        "    df['actual_tags'] = df.apply(collect_tags, axis=1)\n",
        "\n",
        "    # 4. Get the Master List of Allowed Tags\n",
        "    # We need a unique list of ALL possible tags to tell the LLM what it can choose from.\n",
        "    all_unique_tags = sorted(list(set([tag for tags in df['actual_tags'] for tag in tags])))\n",
        "\n",
        "    print(f\"âœ… Data Loaded Successfully!\")\n",
        "    print(f\"Total Tickets: {len(df)}\")\n",
        "    print(f\"Total Unique Tags: {len(all_unique_tags)}\")\n",
        "    print(f\"Sample Tags: {', '.join(all_unique_tags[:10])}...\")\n",
        "\n",
        "    return df, all_unique_tags\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    filename = '/content/aa_dataset-tickets-multi-lang-5-2-50-version.csv'\n",
        "\n",
        "    # Run the function\n",
        "    df_processed, allowed_tags = load_and_preprocess_data(filename)\n",
        "\n",
        "    # Display first few rows to verify\n",
        "    print(\"\\n--- Processed Data Sample ---\")\n",
        "    print(df_processed[['text', 'actual_tags']].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jPRsccgTy5L",
        "outputId": "74100c44-1bb7-4438-8e66-557ab14d4488"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from: /content/aa_dataset-tickets-multi-lang-5-2-50-version.csv\n",
            "âœ… Data Loaded Successfully!\n",
            "Total Tickets: 28587\n",
            "Total Unique Tags: 1255\n",
            "Sample Tags: AI, API, API Integration, AR, AWS, Abrechnungssystem, Access, Access Control, Access Difficulty, Access Issue...\n",
            "\n",
            "--- Processed Data Sample ---\n",
            "                                                text  \\\n",
            "0  Wesentlicher Sicherheitsvorfall \\n Sehr geehrt...   \n",
            "1  Account Disruption \\n Dear Customer Support Te...   \n",
            "2  Query About Smart Home System Integration Feat...   \n",
            "\n",
            "                                       actual_tags  \n",
            "0      [Outage, Disruption, Security, Data Breach]  \n",
            "1  [Tech Support, Disruption, Account, Outage, IT]  \n",
            "2                 [Tech Support, Feature, Product]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the raw CSV data and combine the Subject and Body columns to provide the model with the full context of the user's issue. We also consolidate the scattered tag_1 through tag_8 columns into a single list of actual_tags for each ticket. Finally, we extract the allowed_tagsâ€”the 'universe' of valid categories the model must choose from."
      ],
      "metadata": {
        "id": "1U2KmqTIeOFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your key is set\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "print(\"Checking available models...\")\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "yOZpzBa3V1yy",
        "outputId": "b371c2db-03bb-487f-d90f-0b546758a578"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking available models...\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "def get_zeroshot_prompt(ticket_text, all_tags_list):\n",
        "    \"\"\"\n",
        "    Zero-Shot: Asks the model to tag without seeing any ticket examples.\n",
        "    \"\"\"\n",
        "    return f\"\"\"\n",
        "    Role: You are an automated support ticket tagging system.\n",
        "    Task: specificy the top 3 most relevant tags for the ticket below.\n",
        "\n",
        "    Constraints:\n",
        "    1. Output ONLY a comma-separated list of tags. No explanations.\n",
        "    2. Select tags ONLY from the 'Allowed Tags' list provided.\n",
        "\n",
        "    Allowed Tags:\n",
        "    {\", \".join(all_tags_list)}\n",
        "\n",
        "    Ticket:\n",
        "    \"{ticket_text}\"\n",
        "\n",
        "    Output:\n",
        "    \"\"\"\n",
        "\n",
        "def get_fewshot_prompt(ticket_text, all_tags_list, df_examples):\n",
        "    \"\"\"\n",
        "    Few-Shot: Includes 3 real examples of correctly tagged tickets to guide the model.\n",
        "    \"\"\"\n",
        "    examples_str = \"\"\n",
        "\n",
        "    sample_rows = df_examples.sample(3)\n",
        "\n",
        "    for _, row in sample_rows.iterrows():\n",
        "        tags_str = \", \".join(row['actual_tags'])\n",
        "\n",
        "        examples_str += f'Ticket: \"{row[\"text\"][:200]}...\"\\nTags: {tags_str}\\n---\\n'\n",
        "\n",
        "    return f\"\"\"\n",
        "    Role: You are an automated support ticket tagging system.\n",
        "    Task: specificy the top 3 most relevant tags for the ticket below.\n",
        "\n",
        "    Constraints:\n",
        "    1. Output ONLY a comma-separated list of tags.\n",
        "    2. Select tags ONLY from the 'Allowed Tags' list.\n",
        "    3. Learn from the examples provided below.\n",
        "\n",
        "    Allowed Tags:\n",
        "    {\", \".join(all_tags_list)}\n",
        "\n",
        "    Examples:\n",
        "    {examples_str}\n",
        "\n",
        "    Target Ticket:\n",
        "    \"{ticket_text}\"\n",
        "\n",
        "    Output:\n",
        "    \"\"\"\n",
        "\n",
        "# --- EXECUTION LOOP ---\n",
        "\n",
        "def run_comparison(df, tags_list, num_samples=3):\n",
        "    print(f\"--- Running Comparison on {num_samples} Tickets ---\\n\")\n",
        "\n",
        "\n",
        "    test_set = df.iloc[10:10+num_samples]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, row in test_set.iterrows():\n",
        "        ticket_text = row['text']\n",
        "        actual = row['actual_tags']\n",
        "\n",
        "        print(f\"ðŸŽ« Ticket ID {idx}: {ticket_text[:60]}...\")\n",
        "        print(f\"   âœ… Ground Truth: {actual}\")\n",
        "\n",
        "        # 1. Zero-Shot\n",
        "        try:\n",
        "            p_zero = get_zeroshot_prompt(ticket_text, tags_list)\n",
        "            resp_zero = model.generate_content(p_zero)\n",
        "            pred_zero = [t.strip() for t in resp_zero.text.split(',')]\n",
        "            print(f\"   ðŸ”¹ Zero-Shot:    {pred_zero}\")\n",
        "        except Exception as e:\n",
        "            pred_zero = [\"Error\"]\n",
        "            print(f\"   ðŸ”¹ Zero-Shot:    Error ({e})\")\n",
        "\n",
        "        # 2. Few-Shot (using the full df to pull random examples)\n",
        "        try:\n",
        "            p_few = get_fewshot_prompt(ticket_text, tags_list, df)\n",
        "            resp_few = model.generate_content(p_few)\n",
        "            pred_few = [t.strip() for t in resp_few.text.split(',')]\n",
        "            print(f\"   ðŸ”¸ Few-Shot:     {pred_few}\")\n",
        "        except Exception as e:\n",
        "            pred_few = [\"Error\"]\n",
        "            print(f\"   ðŸ”¸ Few-Shot:     Error ({e})\")\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "        time.sleep(4)\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    if 'df_processed' in locals() and 'allowed_tags' in locals():\n",
        "        run_comparison(df_processed, allowed_tags, num_samples=3)\n",
        "    else:\n",
        "        print(\"Error: Please run the Data Loading step first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "sWMUW4wNUQfN",
        "outputId": "8280ef26-619a-41e3-ce79-f6eb57dac703"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Comparison on 3 Tickets ---\n",
            "\n",
            "ðŸŽ« Ticket ID 10: VPN Access Issue \n",
            " Customer Support,\\n\\nWe are encountering ...\n",
            "   âœ… Ground Truth: ['Tech Support', 'Disruption', 'Network', 'VPN']\n",
            "   ðŸ”¹ Zero-Shot:    ['VPN', 'Access Issue', 'Connectivity']\n",
            "   ðŸ”¸ Few-Shot:     ['VPN', 'Access Issue', 'Technical Support']\n",
            "--------------------------------------------------\n",
            "ðŸŽ« Ticket ID 11: Issue with SaaS Platform Functionality \n",
            " Sehr geehrtes Suppo...\n",
            "   âœ… Ground Truth: ['Disruption', 'Feature', 'Bug', 'Performance']\n",
            "   ðŸ”¹ Zero-Shot:    ['SaaS Platform', 'Performance', 'Disruption']\n",
            "   ðŸ”¸ Few-Shot:     ['SaaS Platform', 'Performance', 'Technical Support']\n",
            "--------------------------------------------------\n",
            "ðŸŽ« Ticket ID 12: Immediate Help Needed: Technical Problem with Cloud SaaS Ser...\n",
            "   âœ… Ground Truth: ['Crash', 'Tech Support', 'Bug', 'Network', 'Disruption', 'Performance', 'Outage']\n",
            "   ðŸ”¹ Zero-Shot:    ['Technical Problem', 'Cloud SaaS', 'Connectivity Issue']\n",
            "   ðŸ”¸ Few-Shot:     ['Technical Problem', 'Performance', 'Cloud SaaS']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tested two prompting strategies using the Gemini 2.5 Flash model:\n",
        "\n",
        "* Zero-Shot: We provide the model with the list of allowed tags and the ticket text, relying entirely on its pre-trained knowledge to classify the issue.\n",
        "\n",
        "* Few-Shot: We dynamically inject 3 real examples of tagged tickets into the prompt. This 'In-Context Learning' teaches the model the specific tagging style and logic of our dataset without updating the model's weights."
      ],
      "metadata": {
        "id": "8lrlMXiieXAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "\n",
        "print(\"--- Loading Data for Fine-Tuning ---\")\n",
        "df = pd.read_csv('/content/aa_dataset-tickets-multi-lang-5-2-50-version.csv', encoding='latin1')\n",
        "\n",
        "\n",
        "df['text'] = df['subject'].fillna('') + \" \" + df['body'].fillna('')\n",
        "\n",
        "\n",
        "tag_cols = [f'tag_{i}' for i in range(1, 9)]\n",
        "df['tags'] = df[tag_cols].apply(lambda x: [str(t) for t in x if pd.notna(t)], axis=1)\n",
        "\n",
        "\n",
        "df = df[df['tags'].map(len) > 0]\n",
        "\n",
        "\n",
        "df = df.sample(2000, random_state=42)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "labels_matrix = mlb.fit_transform(df['tags'])\n",
        "label_list = mlb.classes_\n",
        "\n",
        "print(f\"Training on {len(df)} tickets.\")\n",
        "print(f\"Number of unique tags: {len(label_list)}\")\n",
        "\n",
        "dataset = Dataset.from_dict({\n",
        "    'text': df['text'].tolist(),\n",
        "    'labels': [x.astype(float) for x in labels_matrix]\n",
        "})\n",
        "\n",
        "# Split Train/Test\n",
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "model_id = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "print(\"Tokenizing data...\")\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(label_list),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Training (This may take minutes) ---\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n--- Evaluation ---\")\n",
        "# Predict on Test Set\n",
        "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "preds = torch.sigmoid(torch.tensor(predictions.predictions))\n",
        "\n",
        "pred_tags = []\n",
        "for p in preds:\n",
        "\n",
        "    indices = (p > 0.3).nonzero(as_tuple=True)[0]\n",
        "    pred_tags.append([label_list[i] for i in indices])\n",
        "\n",
        "print(\"\\n--- Fine-Tuned Results Sample ---\")\n",
        "for i in range(3):\n",
        "    print(f\"Ticket: {tokenized_datasets['test'][i]['text'][:60]}...\")\n",
        "    print(f\"Predicted: {pred_tags[i]}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947,
          "referenced_widgets": [
            "d568e19c1c5941b99f8db76e89bbdc32",
            "0028cdc892534174b2f2e638c17f528f",
            "1493cfac3c9649b4b2de9496bf9fcd1d",
            "b465467697874741a74108c7eb2bfb13",
            "9b585164c16c4823affc7eae9e73a3f9",
            "a40b05b0030a46bcba7535366912e863",
            "e8d20f734efd4867b29e13cbde48a2d5",
            "5d2eaa2bbe5f4e80a7a685b1f718066a",
            "24a49d8195d147b0a40724fffe800a6f",
            "a8bc72d0f5cd49909286c815977e1c1f",
            "e664f67bfa4a46c58849751c9438be8e",
            "e829a2d06cea42fd98b8fdb71b6ff07c",
            "9420bc4c45d44992b33ca43c7b60b894",
            "89148a0cc17c40d3b82b0f08cc57cc24",
            "a3f24a6b3a2c4dafbb655dbfdbbe5d30",
            "4b95cc38fc1b4e3f8ceafa01d8c8fb9e",
            "67969a6448e947c48cfd284b621b2480",
            "bfd33096139b4a7691a87f61314cb84e",
            "33fc4a0f12f6478d86036f7a09c87e32",
            "c4b83f63f6f34dfdac0722b2bdfc625a",
            "f9541f61376047cb83ff516db7e705d8",
            "51158cab3cf44830a0ad3fb3a877039b"
          ]
        },
        "id": "jvneftPKYOzY",
        "outputId": "9c0638b2-7661-43ff-d362-53dec7ab296b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Data for Fine-Tuning ---\n",
            "Training on 2000 tickets.\n",
            "Number of unique tags: 331\n",
            "Tokenizing data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d568e19c1c5941b99f8db76e89bbdc32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e829a2d06cea42fd98b8fdb71b6ff07c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-377894521.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Training (This may take minutes) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true&ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madarr417\u001b[0m (\u001b[33madarr417-university-of-management-technology-sialkot-campus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251230_131709-a4jyj0k6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface/runs/a4jyj0k6' target=\"_blank\">copper-voice-10</a></strong> to <a href='https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface' target=\"_blank\">https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface/runs/a4jyj0k6' target=\"_blank\">https://wandb.ai/adarr417-university-of-management-technology-sialkot-campus/huggingface/runs/a4jyj0k6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [600/600 01:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.112054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.069966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.174000</td>\n",
              "      <td>0.063555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-Tuned Results Sample ---\n",
            "Ticket: Verschlusssicherung medizinischer Daten-Systeme Brauche Info...\n",
            "Predicted: ['IT', 'Performance', 'Tech Support']\n",
            "------------------------------\n",
            "Ticket: VerschlÃ¼sselung medizinischer Daten in PostgreSQL Sehr geehr...\n",
            "Predicted: ['IT', 'Performance', 'Tech Support']\n",
            "------------------------------\n",
            "Ticket: Performance Issue in Analytics System The analytics platform...\n",
            "Predicted: ['IT', 'Performance', 'Tech Support']\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train a specific Transformer model (xlm-roberta-base) on our dataset. Unlike the LLM approach, which interprets text freely, this model updates its internal weights to map text patterns directly to our specific tags. We use Multi-Label Binarization to handle tickets that have multiple tags simultaneously"
      ],
      "metadata": {
        "id": "0o7BoVg3eo4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Saving The Model**"
      ],
      "metadata": {
        "id": "bns4NKLAgkY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"./saved_ticket_model\"\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "print(f\"Model saved to {save_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DK2sqqY-eA6K",
        "outputId": "89ae78bd-dfd1-4c14-fb8d-5583ede114b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./saved_ticket_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Insights: LLM Prompting vs. Fine-Tuning**\n",
        "\n",
        "Semantic Understanding vs. Strict Compliance:\n",
        "\n",
        "* Gemini (LLM) demonstrated superior understanding of the content. It correctly identified that a ticket was about \"Connectivity\" or \"SaaS\". However, it often \"hallucinated\" new tags that were semantically correct but didn't exist in our database (e.g., predicting Connectivity instead of Network).\n",
        "\n",
        "* Fine-Tuning demonstrated strict adherence to the schema. It never invented a tag. However, due to class imbalance in the training data, it became conservative, often defaulting to the most common tags (IT, Tech Support) for every ticket.\n",
        "\n",
        "* The \"Hybrid\" Solution is Best:\n",
        "For a production system, a Fine-Tuned model is safer because it guarantees valid outputs. To fix the repetitive predictions seen in this experiment, we would need to train on the full dataset (not just 2,000 rows) and use \"Class Weights\" to penalize the model for ignoring rare tags.\n",
        "\n",
        "* Both approaches handled the mixed English/German dataset successfully without needing a translation step. XLM-RoBERTa is specifically designed for this, while Gemini handles it natively via its large pre-training corpus."
      ],
      "metadata": {
        "id": "cD9JANZde88H"
      }
    }
  ]
}